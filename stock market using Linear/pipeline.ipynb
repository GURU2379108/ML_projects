{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "935e0650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_2652\\977419667.py:12: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 294.08457495230584, Root Mean Squared Error: 17.148894277833364, R^2 Score: 0.9997947324731867\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/hp/Desktop/small projects/stock market using Linear/data/sp500.csv')\n",
    "\n",
    "# Data preparation (as in your original code)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Tommorow'] = df['Close'].shift(-1)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define Target and Features\n",
    "y = df['Tommorow']\n",
    "X = df.drop(['Tommorow', 'Date', 'Dividends', 'Stock Splits'], axis=1)\n",
    "\n",
    "# Define the Scikit-learn Pipeline\n",
    "# This encapsulates the StandardScaler and the RandomForestRegressor.\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the entire pipeline on the training data\n",
    "# This automatically fits the scaler on X_train and then trains the RF model.\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the fitted pipeline on the test data\n",
    "# This automatically transforms the test data and then makes predictions.\n",
    "y_pred_rf = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse=mse ** 0.5\n",
    "r2 = pipeline.score(X_test, y_test)\n",
    "print(f\"Mean Squared Error: {mse}, Root Mean Squared Error: {rmse}, R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b32c712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [09:02:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.902855748108372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [09:02:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Accuracy: 0.9089577739809617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [09:02:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Accuracy: 0.891628020502807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [09:03:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Accuracy: 0.8818647791066634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [09:03:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Accuracy: 0.8948010739565536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 0. Load Data (Placeholder for a working example)\n",
    "# Assume 'df' is your loaded DataFrame with 'Close', 'Open', etc. data.\n",
    "# e.g., df = pd.read_csv('your_stock_data.csv') \n",
    "# If you don't have a file, you must load data first for this code to run.\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 1. Feature Engineering (Outside the sklearn pipeline)\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "# Note: The second 'target' assignment overwrites the first in your original code.\n",
    "# The code below uses the Moving Average Crossover as the target.\n",
    "# df['target'] = (df['Return'].shift(-1) > 0.003).astype(int) \n",
    "df['MA5'] = df['Close'].rolling(5).mean()\n",
    "df['MA10'] = df['Close'].rolling(10).mean()\n",
    "df['target'] = (df['MA5'].shift(-1) > df['MA10'].shift(-1)).astype(int) # This is your target variable y\n",
    "df['MA_Crossover'] = (df['MA5'] > df['MA10']).astype(int) # This is a feature X\n",
    "df['Prev_Close'] = df['Close'].shift(1)\n",
    "\n",
    "# Drop missing values created by rolling means and shifting\n",
    "df = df.dropna()\n",
    "\n",
    "# Define Target and Features DataFrames\n",
    "y = df['target']\n",
    "X = df[['Open', 'High', 'Low', 'Close', 'Volume',\n",
    "        'Return',  'MA5', 'MA10',\n",
    "        'MA_Crossover', 'Prev_Close']]\n",
    "\n",
    "# 2. Define the Scikit-learn Pipeline\n",
    "# This encapsulates the StandardScaler and the XGBoost model.\n",
    "# The 'scaler' component will automatically use fit_transform correctly within the CV loop.\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('xgb', XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=3,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=2,\n",
    "        reg_lambda=4,\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        use_label_encoder=False, # Suppress XGBoost deprecation warning\n",
    "        eval_metric='logloss'    # Use a standard evaluation metric\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3. Time Series Cross-Validation Loop\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "fold = 1\n",
    "\n",
    "# Iterate through the time series splits\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    # Select data using .iloc to handle pandas DataFrames/Series correctly\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Fit the ENTIRE pipeline on the training data for the current fold\n",
    "    # This automatically fits the scaler and then fits the XGBoost model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict using the fitted pipeline\n",
    "    # This automatically transforms the test data using the *training set's* scaling parameters\n",
    "    preds = pipeline.predict(X_test)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy:\", accuracy_score(y_test, preds))\n",
    "    fold += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d0b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
